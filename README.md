Members:\
    Krima Mehta\
    Aaron Exline\
    Sammy Patel\
    Tomisin Fijabi\
    Manasvi Sharma

About:\
    The project is designed to create a program that will recieve video, live feed, or images of a user employing American Sign Language (ASL) and translates them into various letters and numbers.

    This will be achieved by training an AI on images of signs and using it to recognize them from input.

    The process in mind is to take images, convert them to wireframe maps, feed the maps into an AI, and train an algorithm that will recognize ASL.

To Do:
    1. Test different methods of camera usage and make a program that will input feed and recognize hands.\
        - Opens camera :white_check_mark:\
        - Recognizes hand :white_check_mark:\
        - Creates wireframe from hand\
            - Live feed :white_check_mark:\
            - Videos\
            - Photos (IMPORTANT FOR AI TRAINING) :white_check_mark:\
        - Wrap into an actual application (if time allowed)

    2. Convert dataset\
        - Access dataset through API\
        - Feed images from dataset to AI (still have to figure out what we're using and how)\
        - Train AI (also have to figure this out)\
        - Begin testing images
